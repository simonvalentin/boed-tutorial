{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Optional, Tuple, Union\n",
    "\n",
    "import copy\n",
    "import json\n",
    "import numpy\n",
    "import random\n",
    "import torch\n",
    "import pandas\n",
    "import seaborn as sns\n",
    "import scipy.stats as sts\n",
    "from scipy.stats import lognorm\n",
    "from tqdm import tqdm as tqdm\n",
    "\n",
    "# BED imports\n",
    "from boed.networks.fullyconnected import FullyConnected\n",
    "from boed.networks.summstats import NeuralSummStats, CAT_NSS\n",
    "from boed.simulators.bandits import simulate_bandit_batch, sim_bandit_prior\n",
    "from boed.utils.utils_human_participant_study import *\n",
    "\n",
    "# matplotlib imports\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "from matplotlib.colors import to_rgb\n",
    "from matplotlib.patches import Patch\n",
    "from matplotlib import rc\n",
    "%matplotlib inline\n",
    "plt.style.use('default')\n",
    "plt.rcParams['figure.figsize'] = (16.0, 8.0)\n",
    "plt.rcParams.update({'font.size': 16})\n",
    "rc('font', **{'family': 'serif', 'serif': ['Computer Modern']})\n",
    "rc('text', usetex=True)\n",
    "plt.rcParams['text.latex.preamble'] = r'\\usepackage{amsmath}'\n",
    "cycle = plt.rcParams['axes.prop_cycle'].by_key()['color']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load in Human Participant Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load in raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/two_stage_data.json', 'r') as f:\n",
    "    data = json.loads(f.read())\n",
    "    \n",
    "optimal_data = data['optimal']\n",
    "base_data = data['naive']  # naive == baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Specify desired designs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Baseline designs\n",
    "d_md_base = torch.load('../data/designs/md_designs_baseline.pt')\n",
    "d_pe_base = torch.load('../data/designs/pe_designs_baseline.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MD optimal designs\n",
    "d_md_opt = [[0, 0, 0.6], [1, 1, 0]]\n",
    "\n",
    "# PE optimal designs\n",
    "d_pe_wslts_opt = [[0, 0, 1], [0, 1, 1], [1, 0, 1]]\n",
    "d_pe_aeg_opt = [[1, 0, 0], [0, 0, 1], [1, 0, 1]]\n",
    "d_pe_gls_opt = [[0, 1, 0], [0, 0, 1], [0, 0, 1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transform raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get MD data for optimal and baseline users\n",
    "optimal_md_only = [get_md_data_only(user, md_blocks=2) for user in optimal_data]\n",
    "base_md_only = [get_md_data_only(user, md_blocks=2) for user in base_data]\n",
    "\n",
    "# transform data for optimal and baseline users to be consistent\n",
    "optimal_md_transf = [transform_data(user, d_md_opt) for user in optimal_md_only]\n",
    "base_md_transf = [transform_data(user, d_md_base[user['conditionS1']], num_arms=3) for user in base_md_only]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get PE data for optimal and baseline users\n",
    "optimal_pe_only = [get_pe_data_only(user, md_blocks=2) for user in optimal_data]\n",
    "base_pe_only = [get_pe_data_only(user, md_blocks=2) for user in base_data]\n",
    "\n",
    "# transform data for optimal users to be consistent\n",
    "optimal_pe_wslts_transf = list()\n",
    "optimal_pe_aeg_transf = list()\n",
    "optimal_pe_gls_transf = list()\n",
    "for user in optimal_pe_only:\n",
    "    if user['conditionS2'] == 'wslts':\n",
    "        transf = transform_data(user, d_pe_wslts_opt, num_arms=3)\n",
    "        optimal_pe_wslts_transf.append(transf)\n",
    "    elif user['conditionS2'] == 'aeg':\n",
    "        transf = transform_data(user, d_pe_aeg_opt, num_arms=3)\n",
    "        optimal_pe_aeg_transf.append(transf)\n",
    "    elif user['conditionS2'] == 'gls':\n",
    "        transf = transform_data(user, d_pe_gls_opt, num_arms=3)\n",
    "        optimal_pe_gls_transf.append(transf)\n",
    "        \n",
    "# transform data for baseline users to be consistent\n",
    "base_pe_transf = [transform_data(user, d_pe_base[user['conditionS1']], num_arms=3) for user in base_pe_only]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load in trained neural networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MD Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelparams_md_loading = {\n",
    "    'layers': 2,\n",
    "    'hidden': [32, 32],\n",
    "    'num_measurements': 2,\n",
    "    'summ_L': 2,\n",
    "    'summ_H': [64, 32],\n",
    "    'summ_out': 6\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the models for optimal designs\n",
    "model_md_opt_list = list()\n",
    "model_summ_md_opt_list = list()\n",
    "for i in range(50):\n",
    "    \n",
    "    fcp = \"../data/models/md_model_trained_optimal_new_repeat{}.pt\".format(i)\n",
    "    summp = \"../data/models/md_model_summ_trained_optimal_new_repeat{}.pt\".format(i)\n",
    "    \n",
    "    model_tr, model_summ_tr = get_trained_models(modelparams_md_loading, fcp, summp, dim1=1)\n",
    "    \n",
    "    model_md_opt_list.append(model_tr)\n",
    "    model_summ_md_opt_list.append(model_summ_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the models for baseline designs\n",
    "model_md_base_dict = dict((str(i), list()) for i in range(10))\n",
    "model_summ_md_base_dict = dict((str(i), list()) for i in range(10))\n",
    "for job_id in range(10):\n",
    "    for i in range(10):\n",
    "\n",
    "        fcp = \"../data/models/md_model_trained_baseline{}_ensemble_new_repeat{}.pt\".format(i, job_id)\n",
    "        summp = \"../data/models/md_model_summ_trained_baseline{}_ensemble_new_repeat{}.pt\".format(i, job_id)\n",
    "\n",
    "        model_tr, model_summ_tr = get_trained_models(modelparams_md_loading, fcp, summp, dim1=1)\n",
    "                \n",
    "        model_md_base_dict[str(i)].append(model_tr)\n",
    "        model_summ_md_base_dict[str(i)].append(model_summ_tr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PE-WSLTS Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelparams_pe_wslts_loading = {\n",
    "    'layers': 2,\n",
    "    'hidden': [64, 32],\n",
    "    'num_measurements': 3,\n",
    "    'summ_L': 2,\n",
    "    'summ_H': [64, 32],\n",
    "    'summ_out': 8\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the models for optimal designs\n",
    "model_pe_wslts_opt_list = list()\n",
    "model_summ_pe_wslts_opt_list = list()\n",
    "for i in range(50):\n",
    "    \n",
    "    fcp = \"../data/models/pe_wslts_model_trained_optimal_ensemble_new_repeat{}.pt\".format(i)\n",
    "    summp = \"../data/models/pe_wslts_model_summ_trained_optimal_ensemble_new_repeat{}.pt\".format(i)\n",
    "    \n",
    "    model_tr, model_summ_tr = get_trained_models(modelparams_pe_wslts_loading, fcp, summp, dim1=3)\n",
    "    \n",
    "    model_pe_wslts_opt_list.append(model_tr)\n",
    "    model_summ_pe_wslts_opt_list.append(model_summ_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the models for baseline designs\n",
    "model_pe_wslts_base_dict = dict((str(i), list()) for i in range(10))\n",
    "model_summ_pe_wslts_base_dict = dict((str(i), list()) for i in range(10))\n",
    "for job_id in range(10):\n",
    "    for i in range(10):\n",
    "\n",
    "        fcp = \"../data/models/pe_wslts_model_trained_baseline{}_ensemble_new_repeat{}.pt\".format(i, job_id)\n",
    "        summp = \"../data/models/pe_wslts_model_summ_trained_baseline{}_ensemble_new_repeat{}.pt\".format(i, job_id)\n",
    "\n",
    "        model_tr, model_summ_tr = get_trained_models(modelparams_pe_wslts_loading, fcp, summp, dim1=3)\n",
    "                \n",
    "        model_pe_wslts_base_dict[str(i)].append(model_tr)\n",
    "        model_summ_pe_wslts_base_dict[str(i)].append(model_summ_tr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PE-AEG Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelparams_pe_aeg_loading = {\n",
    "    'layers': 2,\n",
    "    'hidden': [64, 32],\n",
    "    'num_measurements': 3,\n",
    "    'summ_L': 2,\n",
    "    'summ_H': [64, 32],\n",
    "    'summ_out': 6\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the models for optimal designs\n",
    "model_pe_aeg_opt_list = list()\n",
    "model_summ_pe_aeg_opt_list = list()\n",
    "for i in range(50):\n",
    "    \n",
    "    fcp = \"../data/models/pe_aeg_model_trained_optimal_ensemble_new_repeat{}.pt\".format(i)\n",
    "    summp = \"../data/models/pe_aeg_model_summ_trained_optimal_ensemble_new_repeat{}.pt\".format(i)\n",
    "    \n",
    "    model_tr, model_summ_tr = get_trained_models(modelparams_pe_aeg_loading, fcp, summp, dim1=2)\n",
    "    \n",
    "    model_pe_aeg_opt_list.append(model_tr)\n",
    "    model_summ_pe_aeg_opt_list.append(model_summ_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the models for baseline designs\n",
    "model_pe_aeg_base_dict = dict((str(i), list()) for i in range(10))\n",
    "model_summ_pe_aeg_base_dict = dict((str(i), list()) for i in range(10))\n",
    "for job_id in range(10):\n",
    "    for i in range(10):\n",
    "\n",
    "        fcp = \"../data/models/pe_aeg_model_trained_baseline{}_ensemble_new_repeat{}.pt\".format(i, job_id)\n",
    "        summp = \"../data/models/pe_aeg_model_summ_trained_baseline{}_ensemble_new_repeat{}.pt\".format(i, job_id)\n",
    "\n",
    "        model_tr, model_summ_tr = get_trained_models(modelparams_pe_aeg_loading, fcp, summp, dim1=2)\n",
    "                \n",
    "        model_pe_aeg_base_dict[str(i)].append(model_tr)\n",
    "        model_summ_pe_aeg_base_dict[str(i)].append(model_summ_tr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PE-GLS Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelparams_pe_gls_loading = {\n",
    "    'layers': 2,\n",
    "    'hidden': [64, 32],\n",
    "    'num_measurements': 3,\n",
    "    'summ_L': 2,\n",
    "    'summ_H': [64, 32],\n",
    "    'summ_out': 8\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the models\n",
    "model_pe_gls_opt_list = list()\n",
    "model_summ_pe_gls_opt_list = list()\n",
    "for i in range(50):\n",
    "    \n",
    "    fcp = \"../data/models/pe_gls_model_trained_optimal_ensemble_new_repeat{}.pt\".format(i)\n",
    "    summp = \"../data/models/pe_gls_model_summ_trained_optimal_ensemble_new_repeat{}.pt\".format(i)\n",
    "    \n",
    "    model_tr, model_summ_tr = get_trained_models(modelparams_pe_gls_loading, fcp, summp, dim1=5)\n",
    "    \n",
    "    model_pe_gls_opt_list.append(model_tr)\n",
    "    model_summ_pe_gls_opt_list.append(model_summ_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the models\n",
    "model_pe_gls_base_dict = dict((str(i), list()) for i in range(10))\n",
    "model_summ_pe_gls_base_dict = dict((str(i), list()) for i in range(10))\n",
    "for job_id in range(10):\n",
    "    for i in range(10):\n",
    "\n",
    "        fcp = \"../data/models/pe_gls_model_trained_baseline{}_ensemble_new_repeat{}.pt\".format(i, job_id)\n",
    "        summp = \"../data/models/pe_gls_model_summ_trained_baseline{}_ensemble_new_repeat{}.pt\".format(i, job_id)\n",
    "\n",
    "        model_tr, model_summ_tr = get_trained_models(modelparams_pe_gls_loading, fcp, summp, dim1=5)\n",
    "                \n",
    "        model_pe_gls_base_dict[str(i)].append(model_tr)\n",
    "        model_summ_pe_gls_base_dict[str(i)].append(model_summ_tr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute Posterior Distributions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MD Posteriors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████| 166/166 [00:04<00:00, 38.89it/s]\n"
     ]
    }
   ],
   "source": [
    "# OPTIMAL\n",
    "posts_md_opt_ensemble = list()\n",
    "for user in tqdm(optimal_md_transf):\n",
    "        \n",
    "    # real-world observation\n",
    "    y_obs = combine_choices_rewards(user).unsqueeze(0)\n",
    "    \n",
    "    posts_single_network = list()\n",
    "    for i in tqdm(range(len(model_md_opt_list)), disable=True):\n",
    "        \n",
    "        model_tr = model_md_opt_list[i]\n",
    "        model_summ_tr = model_summ_md_opt_list[i]\n",
    "        \n",
    "        Sy_obs = model_summ_tr(y_obs)\n",
    "        \n",
    "        X = torch.tensor(numpy.arange(0, 3).reshape(-1, 1), dtype=torch.float, device=device)\n",
    "        X.to(X)\n",
    "        Y = torch.cat(len(X)*[Sy_obs])\n",
    "        Y.to(device);\n",
    "        \n",
    "        T = model_tr(X, Y).data.numpy().reshape(-1)\n",
    "        prior_weight = 1 / 3.\n",
    "        post_weights = numpy.exp(T - 1) * prior_weight\n",
    "        post_norm = post_weights / numpy.sum(post_weights)\n",
    "        posts_single_network.append(post_norm)\n",
    "        \n",
    "    posts_md_opt_ensemble.append(posts_single_network)\n",
    "posts_md_opt_ensemble = numpy.array(posts_md_opt_ensemble)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████| 160/160 [00:00<00:00, 177.28it/s]\n"
     ]
    }
   ],
   "source": [
    "# BASELINE\n",
    "posts_md_base_ensemble = list()\n",
    "for user in tqdm(base_md_transf):\n",
    "    \n",
    "    condition = user['conditionS1']\n",
    "    \n",
    "    # real-world observation\n",
    "    y_obs = combine_choices_rewards(user).unsqueeze(0)\n",
    "    \n",
    "    posts_single_network = list()\n",
    "    for i in tqdm(range(len(model_md_base_dict[condition])), disable=True):\n",
    "        \n",
    "        model_tr = model_md_base_dict[condition][i]\n",
    "        model_summ_tr = model_summ_md_base_dict[condition][i]\n",
    "        \n",
    "        Sy_obs = model_summ_tr(y_obs)\n",
    "        \n",
    "        X = torch.tensor(numpy.arange(0, 3).reshape(-1, 1), dtype=torch.float, device=device)\n",
    "        X.to(X)\n",
    "        Y = torch.cat(len(X)*[Sy_obs])\n",
    "        Y.to(device);\n",
    "        \n",
    "        T = model_tr(X, Y).data.numpy().reshape(-1)\n",
    "        prior_weight = 1 / 3.\n",
    "        post_weights = numpy.exp(T - 1) * prior_weight\n",
    "        post_norm = post_weights / numpy.sum(post_weights)\n",
    "        posts_single_network.append(post_norm)\n",
    "        \n",
    "    posts_md_base_ensemble.append(posts_single_network)\n",
    "posts_md_base_ensemble = numpy.array(posts_md_base_ensemble)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal model indicators for each participant:\n",
      "[2 2 2 0 0 0 0 0 2 0 1 2 2 2 2 1 2 0 1 0 1 2 0 2 0 2 2 0 0 2 0 2 0 2 1 2 1\n",
      " 1 2 2 2 0 0 2 0 0 2 0 2 2 2 2 2 0 0 0 0 2 2 2 2 2 2 0 1 0 0 2 2 1 0 0 2 1\n",
      " 2 0 0 2 2 2 0 0 2 0 2 2 1 0 0 2 2 1 0 0 2 2 2 2 0 2 2 1 0 2 2 2 0 2 2 2 1\n",
      " 0 2 2 2 0 0 2 2 2 0 1 0 0 0 1 2 2 2 2 2 2 0 2 0 0 0 1 0 2 2 0 0 2 1 1 0 2\n",
      " 1 0 2 2 0 2 2 2 1 2 2 1]\n"
     ]
    }
   ],
   "source": [
    "baseline_md_postargmax = numpy.argmax(numpy.mean(posts_md_base_ensemble, axis=1), axis=1)\n",
    "print('Optimal model indicators for each participant:')\n",
    "print(baseline_md_postargmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_dict_opt = {'wslts': 0, 'aeg': 0, 'gls': 0}\n",
    "for user in optimal_md_transf:\n",
    "    count_dict_opt[user['conditionS2']] += 1\n",
    "    \n",
    "count_dict_base = {'wslts': 0, 'aeg': 0, 'gls': 0}\n",
    "for user_ind in baseline_md_postargmax:\n",
    "    if user_ind == 0:\n",
    "        count_dict_base['wslts'] += 1\n",
    "    elif user_ind == 1:\n",
    "        count_dict_base['aeg'] += 1\n",
    "    elif user_ind == 2:\n",
    "        count_dict_base['gls'] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MD phase allocation of participants in the optimal design group:\n",
      "{'wslts': 62, 'aeg': 75, 'gls': 29}\n",
      "MD phase allocation of participants in the baseline design group:\n",
      "{'wslts': 57, 'aeg': 22, 'gls': 81}\n"
     ]
    }
   ],
   "source": [
    "print('MD phase allocation of participants in the optimal design group:')\n",
    "print(count_dict_opt)\n",
    "print('MD phase allocation of participants in the baseline design group:')\n",
    "print(count_dict_base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MD phase fractional allocation of participants in the optimal design group:\n",
      "{'wslts': 0.373, 'aeg': 0.452, 'gls': 0.175}\n",
      "MD phase fractional allocation of participants in the baseline design group:\n",
      "{'wslts': 0.356, 'aeg': 0.138, 'gls': 0.506}\n"
     ]
    }
   ],
   "source": [
    "for key, value in count_dict_opt.items():\n",
    "    count_dict_opt[key] = round(value / len(optimal_md_transf), 3)\n",
    "for key, value in count_dict_base.items():\n",
    "    count_dict_base[key] = round(value / len(baseline_md_postargmax), 3)\n",
    "print('MD phase fractional allocation of participants in the optimal design group:')\n",
    "print(count_dict_opt)\n",
    "print('MD phase fractional allocation of participants in the baseline design group:')\n",
    "print(count_dict_base)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PE-WSLTS Posteriors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get regular prior samples\n",
    "SIMMODEL = 0\n",
    "DATASIZE = 5_000 # do 50_000 for best results\n",
    "prior_0 = sim_bandit_prior(DATASIZE, prior='uninformed', simmodel=SIMMODEL)\n",
    "\n",
    "# number of re-samples\n",
    "K = 10_000  # do 100_000 for best results\n",
    "\n",
    "# bins for histograms\n",
    "BINS=50\n",
    "bins_all_0 = [\n",
    "    numpy.linspace(0, 1, BINS),\n",
    "    numpy.linspace(0, 1, BINS),\n",
    "    numpy.linspace(0.01, 5, BINS)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████| 62/62 [03:11<00:00,  3.09s/it]\n"
     ]
    }
   ],
   "source": [
    "# obtain posterior histograms and correlations for optimal designs\n",
    "posts_pe_wslts_ensemble, corrs_pe_wslts_ensemble = get_pe_posterior_histograms_optimal(\n",
    "    users=optimal_pe_wslts_transf,\n",
    "    model_list=model_pe_wslts_opt_list,\n",
    "    model_summ_list=model_summ_pe_wslts_opt_list,\n",
    "    prior_samples=prior_0,\n",
    "    hist_bins_list=bins_all_0,\n",
    "    simmodel=SIMMODEL,\n",
    "    num_resample=K\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████| 160/160 [00:34<00:00,  4.70it/s]\n"
     ]
    }
   ],
   "source": [
    "# obtain posterior histograms and correlations for baseline designs\n",
    "posts_pe_wslts_ensemble_base, corrs_pe_wslts_ensemble_base = get_pe_posterior_histograms_baseline(\n",
    "    users=base_pe_transf,\n",
    "    model_dict=model_pe_wslts_base_dict,\n",
    "    model_summ_dict=model_summ_pe_wslts_base_dict,\n",
    "    prior_samples=prior_0,\n",
    "    hist_bins_list=bins_all_0,\n",
    "    simmodel=SIMMODEL,\n",
    "    num_resample=K,\n",
    "    baseline_allocation=baseline_md_postargmax\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PE-AEG Posteriors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get regular prior samples\n",
    "SIMMODEL = 1\n",
    "DATASIZE = 5_000 # do 50_000 for best results\n",
    "prior_1 = sim_bandit_prior(DATASIZE, prior='uninformed', simmodel=SIMMODEL)\n",
    "\n",
    "# number of re-samples\n",
    "K = 10_000  # do 100_000 for best results\n",
    "\n",
    "# bins for histograms\n",
    "BINS=50\n",
    "bins_all_1 = [\n",
    "    numpy.linspace(0, 1, BINS),\n",
    "    numpy.linspace(0, 1, BINS),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████| 75/75 [04:25<00:00,  3.54s/it]\n"
     ]
    }
   ],
   "source": [
    "# obtain posterior histograms and correlations for optimal designs\n",
    "posts_pe_aeg_ensemble, corrs_pe_aeg_ensemble = get_pe_posterior_histograms_optimal(\n",
    "    users=optimal_pe_aeg_transf,\n",
    "    model_list=model_pe_aeg_opt_list,\n",
    "    model_summ_list=model_summ_pe_aeg_opt_list,\n",
    "    prior_samples=prior_1,\n",
    "    hist_bins_list=bins_all_1,\n",
    "    simmodel=SIMMODEL,\n",
    "    num_resample=K\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████| 160/160 [00:18<00:00,  8.83it/s]\n"
     ]
    }
   ],
   "source": [
    "# obtain posterior histograms and correlations for baseline designs\n",
    "posts_pe_aeg_ensemble_base, corrs_pe_aeg_ensemble_base = get_pe_posterior_histograms_baseline(\n",
    "    users=base_pe_transf,\n",
    "    model_dict=model_pe_aeg_base_dict,\n",
    "    model_summ_dict=model_summ_pe_aeg_base_dict,\n",
    "    prior_samples=prior_1,\n",
    "    hist_bins_list=bins_all_1,\n",
    "    simmodel=SIMMODEL,\n",
    "    num_resample=K,\n",
    "    baseline_allocation=baseline_md_postargmax\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PE-GLS Posteriors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get regular prior samples\n",
    "SIMMODEL = 2\n",
    "DATASIZE = 5_000 # do 50_000 for best results\n",
    "prior_2 = sim_bandit_prior(DATASIZE, prior='uninformed', simmodel=SIMMODEL)\n",
    "\n",
    "# number of re-samples\n",
    "K = 10_000  # do 100_000 for best results\n",
    "\n",
    "# bins for histograms\n",
    "BINS=50\n",
    "bins_all_2 = [\n",
    "    numpy.linspace(0, 1, BINS),\n",
    "    numpy.linspace(0, 1, BINS),\n",
    "    numpy.linspace(0, 1, BINS),\n",
    "    numpy.linspace(0, 1, BINS),\n",
    "    numpy.linspace(0, 1, BINS)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████| 29/29 [01:45<00:00,  3.64s/it]\n"
     ]
    }
   ],
   "source": [
    "# obtain posterior histograms and correlations for optimal designs\n",
    "posts_pe_gls_ensemble, corrs_pe_gls_ensemble = get_pe_posterior_histograms_optimal(\n",
    "    users=optimal_pe_gls_transf,\n",
    "    model_list=model_pe_gls_opt_list,\n",
    "    model_summ_list=model_summ_pe_gls_opt_list,\n",
    "    prior_samples=prior_2,\n",
    "    hist_bins_list=bins_all_2,\n",
    "    simmodel=SIMMODEL,\n",
    "    num_resample=K\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████| 160/160 [01:00<00:00,  2.66it/s]\n"
     ]
    }
   ],
   "source": [
    "# obtain posterior histograms and correlations for baseline designs\n",
    "posts_pe_gls_ensemble_base, corrs_pe_gls_ensemble_base = get_pe_posterior_histograms_baseline(\n",
    "    users=base_pe_transf,\n",
    "    model_dict=model_pe_gls_base_dict,\n",
    "    model_summ_dict=model_summ_pe_gls_base_dict,\n",
    "    prior_samples=prior_2,\n",
    "    hist_bins_list=bins_all_2,\n",
    "    simmodel=SIMMODEL,\n",
    "    num_resample=K,\n",
    "    baseline_allocation=baseline_md_postargmax\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute Posterior Entropies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "md_entropies_opt = numpy.array([sts.entropy(p, axis=1) for p in posts_md_opt_ensemble])\n",
    "md_entropies_base = numpy.array([sts.entropy(p, axis=1) for p in posts_md_base_ensemble])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## WSLTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simmodel\n",
    "SIMMODEL=0\n",
    "\n",
    "# number of re-samples\n",
    "K = 1_000  # Select at least 10_000 for best results\n",
    "\n",
    "# bins for histograms\n",
    "N_GRID=10  # Select at least 30 for best results\n",
    "grid_all_0 = [\n",
    "    numpy.linspace(0, 1, N_GRID),\n",
    "    numpy.linspace(0, 1, N_GRID),\n",
    "    numpy.linspace(0.01, 5, N_GRID)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████| 62/62 [02:54<00:00,  2.81s/it]\n"
     ]
    }
   ],
   "source": [
    "# obtain posterior histograms and correlations for optimal designs\n",
    "entropy_pe_wslts_avg, entropy_pe_wslts_ind = get_pe_entropies_optimal(\n",
    "    users=optimal_pe_wslts_transf,\n",
    "    model_list=model_pe_wslts_opt_list,\n",
    "    model_summ_list=model_summ_pe_wslts_opt_list,\n",
    "    prior_samples=prior_0,\n",
    "    grid_list=grid_all_0,\n",
    "    simmodel=SIMMODEL,\n",
    "    num_resample=K\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████| 160/160 [00:34<00:00,  4.64it/s]\n"
     ]
    }
   ],
   "source": [
    "# obtain posterior histograms and correlations for optimal designs\n",
    "entropy_pe_wslts_base_avg, entropy_pe_wslts_base_ind = get_pe_entropies_baseline(\n",
    "    users=base_pe_transf,\n",
    "    model_dict=model_pe_wslts_base_dict,\n",
    "    model_summ_dict=model_summ_pe_wslts_base_dict,\n",
    "    prior_samples=prior_0,\n",
    "    grid_list=grid_all_0,\n",
    "    simmodel=SIMMODEL,\n",
    "    num_resample=K,\n",
    "    baseline_allocation=baseline_md_postargmax\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AEG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simmodel\n",
    "SIMMODEL=1\n",
    "\n",
    "# number of re-samples\n",
    "K = 1_000  # Select at least 10_000 for best results\n",
    "\n",
    "# bins for histograms\n",
    "N_GRID=10  # Select at least 100 for best results\n",
    "grid_all_1 = [\n",
    "    numpy.linspace(0, 1, N_GRID),\n",
    "    numpy.linspace(0, 1, N_GRID),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████| 75/75 [02:34<00:00,  2.06s/it]\n"
     ]
    }
   ],
   "source": [
    "# obtain posterior histograms and correlations for optimal designs\n",
    "entropy_pe_aeg_avg, entropy_pe_aeg_ind = get_pe_entropies_optimal(\n",
    "    users=optimal_pe_aeg_transf,\n",
    "    model_list=model_pe_aeg_opt_list,\n",
    "    model_summ_list=model_summ_pe_aeg_opt_list,\n",
    "    prior_samples=prior_1,\n",
    "    grid_list=grid_all_1,\n",
    "    simmodel=SIMMODEL,\n",
    "    num_resample=K\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████| 160/160 [00:09<00:00, 16.85it/s]\n"
     ]
    }
   ],
   "source": [
    "# obtain posterior histograms and correlations for optimal designs\n",
    "entropy_pe_aeg_base_avg, entropy_pe_aeg_base_ind = get_pe_entropies_baseline(\n",
    "    users=base_pe_transf,\n",
    "    model_dict=model_pe_aeg_base_dict,\n",
    "    model_summ_dict=model_summ_pe_aeg_base_dict,\n",
    "    prior_samples=prior_1,\n",
    "    grid_list=grid_all_1,\n",
    "    simmodel=SIMMODEL,\n",
    "    num_resample=K,\n",
    "    baseline_allocation=baseline_md_postargmax\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GLS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simmodel\n",
    "SIMMODEL=2\n",
    "\n",
    "# number of re-samples\n",
    "K = 100  # Select at least 10_000 for best results\n",
    "\n",
    "# bins for histograms\n",
    "N_GRID=10  # Select at least 10 for best results\n",
    "grid_all_2 = [\n",
    "    numpy.linspace(0, 1, N_GRID),\n",
    "    numpy.linspace(0, 1, N_GRID),\n",
    "    numpy.linspace(0, 1, N_GRID),\n",
    "    numpy.linspace(0, 1, N_GRID),\n",
    "    numpy.linspace(0, 1, N_GRID),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████| 29/29 [08:56<00:00, 18.49s/it]\n"
     ]
    }
   ],
   "source": [
    "# obtain posterior histograms and correlations for optimal designs\n",
    "entropy_pe_gls_avg, entropy_pe_gls_ind = get_pe_entropies_optimal(\n",
    "    users=optimal_pe_gls_transf,\n",
    "    model_list=model_pe_gls_opt_list,\n",
    "    model_summ_list=model_summ_pe_gls_opt_list,\n",
    "    prior_samples=prior_2,\n",
    "    grid_list=grid_all_2,\n",
    "    simmodel=SIMMODEL,\n",
    "    num_resample=K\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████| 160/160 [05:18<00:00,  1.99s/it]\n"
     ]
    }
   ],
   "source": [
    "# obtain posterior histograms and correlations for optimal designs\n",
    "entropy_pe_gls_base_avg, entropy_pe_gls_base_ind = get_pe_entropies_baseline(\n",
    "    users=base_pe_transf,\n",
    "    model_dict=model_pe_gls_base_dict,\n",
    "    model_summ_dict=model_summ_pe_gls_base_dict,\n",
    "    prior_samples=prior_2,\n",
    "    grid_list=grid_all_2,\n",
    "    simmodel=SIMMODEL,\n",
    "    num_resample=K,\n",
    "    baseline_allocation=baseline_md_postargmax\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Posterior Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MD Data\n",
    "md_savedata = {\n",
    "    'posts_opt_ensemble': posts_md_opt_ensemble,\n",
    "    'user_opt_data': optimal_md_transf,\n",
    "    'posts_base_ensemble': posts_md_base_ensemble,\n",
    "    'user_base_data': base_md_transf,\n",
    "    'postargmax_base': baseline_md_postargmax,\n",
    "    'post_shapes': ['num users', 'ensemble repeats', 'num indicators']}\n",
    "\n",
    "# PE WSLTS Data\n",
    "pe_wslts_savedata = {\n",
    "    'posts_opt_ensemble': posts_pe_wslts_ensemble,\n",
    "    'corrs_opt_ensemble': corrs_pe_wslts_ensemble,\n",
    "    'user_opt_data': optimal_pe_wslts_transf,\n",
    "    'posts_base_ensemble': posts_pe_wslts_ensemble_base,\n",
    "    'corrs_base_ensemble': corrs_pe_wslts_ensemble_base,\n",
    "    'user_base_data': base_pe_transf,\n",
    "    'prior_samples': prior_0,\n",
    "    'bins': bins_all_0,\n",
    "    'samples': K,\n",
    "    'post_shapes': ['num users', 'ensemble repeats', 'num parameters', 'num_bins']}\n",
    "\n",
    "# PE AEG Data\n",
    "pe_aeg_savedata = {\n",
    "    'posts_opt_ensemble': posts_pe_aeg_ensemble,\n",
    "    'corrs_opt_ensemble': corrs_pe_aeg_ensemble,\n",
    "    'user_opt_data': optimal_pe_aeg_transf,\n",
    "    'posts_base_ensemble': posts_pe_aeg_ensemble_base,\n",
    "    'corrs_base_ensemble': corrs_pe_aeg_ensemble_base,\n",
    "    'user_base_data': base_pe_transf,\n",
    "    'prior_samples': prior_1,\n",
    "    'bins': bins_all_1,\n",
    "    'samples': K,\n",
    "    'post_shapes': ['num users', 'ensemble repeats', 'num parameters', 'num_bins']}\n",
    "\n",
    "# PE GLS Data\n",
    "pe_gls_savedata = {\n",
    "    'posts_opt_ensemble': posts_pe_gls_ensemble,\n",
    "    'corrs_opt_ensemble': corrs_pe_gls_ensemble,\n",
    "    'user_opt_data': optimal_pe_gls_transf,\n",
    "    'posts_base_ensemble': posts_pe_gls_ensemble_base,\n",
    "    'corrs_base_ensemble': corrs_pe_gls_ensemble_base,\n",
    "    'user_base_data': base_pe_transf,\n",
    "    'prior_samples': prior_2,\n",
    "    'bins': bins_all_2,\n",
    "    'samples': K,\n",
    "    'post_shapes': ['num users', 'ensemble repeats', 'num parameters', 'num_bins']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(md_savedata, '../data/md_posts_savedata.pt')\n",
    "torch.save(pe_wslts_savedata, '../data/pe_wslts_posts_savedata.pt')\n",
    "torch.save(pe_aeg_savedata, '../data/pe_aeg_posts_savedata.pt')\n",
    "torch.save(pe_gls_savedata, '../data/pe_gls_posts_savedata.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entropy Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MD Entropy Data\n",
    "md_entropies_data = {\n",
    "    'opt_ind': md_entropies_opt,\n",
    "    'base_ind': md_entropies_base,\n",
    "}\n",
    "torch.save(md_entropies_data, '../data/md_entropies.pt')\n",
    "\n",
    "# PE WSLTS Entropy Data\n",
    "pe_wslts_entropies_data = {\n",
    "    'opt_avg': entropy_pe_wslts_avg,\n",
    "    'base_avg': entropy_pe_wslts_base_avg,\n",
    "    'opt_ind': entropy_pe_wslts_ind,\n",
    "    'base_ind': entropy_pe_wslts_base_ind,\n",
    "    'extra': {'K': 1_000, 'N_GRID': 10}\n",
    "}\n",
    "torch.save(pe_wslts_entropies_data, '../data/pe_wslts_entropies.pt')\n",
    "\n",
    "# PE AEG Entropy Data\n",
    "pe_aeg_entropies_data = {\n",
    "    'opt_avg': entropy_pe_aeg_avg,\n",
    "    'base_avg': entropy_pe_aeg_base_avg,\n",
    "    'opt_ind': entropy_pe_aeg_ind,\n",
    "    'base_ind': entropy_pe_aeg_base_ind,\n",
    "    'extra': {'K': 1_000, 'N_GRID': 10}\n",
    "}\n",
    "torch.save(pe_wslts_entropies_data, '../data/pe_aeg_entropies.pt')\n",
    "\n",
    "# PE GLS Entropy Data\n",
    "pe_gls_entropies_data = {\n",
    "    'opt_avg': entropy_pe_gls_avg,\n",
    "    'base_avg': entropy_pe_gls_base_avg,\n",
    "    'opt_ind': entropy_pe_gls_ind,\n",
    "    'base_ind': entropy_pe_gls_base_ind,\n",
    "    'extra': {'K': 100, 'N_GRID': 10}\n",
    "}\n",
    "torch.save(pe_wslts_entropies_data, '../data/pe_gls_entropies.pt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:boed-tutorial]",
   "language": "python",
   "name": "conda-env-boed-tutorial-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
